{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting TRY mentions in sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chem_word</th>\n",
       "      <th>prod_word</th>\n",
       "      <th>chem_word_idx</th>\n",
       "      <th>prod_word_idx</th>\n",
       "      <th>sentence</th>\n",
       "      <th>tokens</th>\n",
       "      <th>between_tokens</th>\n",
       "      <th>chems</th>\n",
       "      <th>prods</th>\n",
       "      <th>chem_pos_word</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alpha-D-glucose</td>\n",
       "      <td>0.2mM</td>\n",
       "      <td>[5, 10]</td>\n",
       "      <td>[3, 4]</td>\n",
       "      <td>As  as 0.2mM added alpha-D-glucose (0.4mM alph...</td>\n",
       "      <td>[As,  , as, 0.2mM, added, alpha, -, D, -, gluc...</td>\n",
       "      <td>[added]</td>\n",
       "      <td>[27*#*28, 12*#*17, 5*#*10, 30*#*36]</td>\n",
       "      <td>[11*#*12, 3*#*4, 29*#*30]</td>\n",
       "      <td>{'5*#*10': 'alpha-D-glucose', '12*#*17': 'alph...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alpha-D-glucose</td>\n",
       "      <td>25mM</td>\n",
       "      <td>[5, 10]</td>\n",
       "      <td>[29, 30]</td>\n",
       "      <td>As  as 0.2mM added alpha-D-glucose (0.4mM alph...</td>\n",
       "      <td>[As,  , as, 0.2mM, added, alpha, -, D, -, gluc...</td>\n",
       "      <td>[(, 0.4mM, alpha, -, D, -, xylose, ),  , incre...</td>\n",
       "      <td>[27*#*28, 12*#*17, 5*#*10, 30*#*36]</td>\n",
       "      <td>[11*#*12, 3*#*4, 29*#*30]</td>\n",
       "      <td>{'5*#*10': 'alpha-D-glucose', '12*#*17': 'alph...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>alpha-D-xylose</td>\n",
       "      <td>0.2mM</td>\n",
       "      <td>[12, 17]</td>\n",
       "      <td>[3, 4]</td>\n",
       "      <td>As  as 0.2mM added alpha-D-glucose (0.4mM alph...</td>\n",
       "      <td>[As,  , as, 0.2mM, added, alpha, -, D, -, gluc...</td>\n",
       "      <td>[added, alpha, -, D, -, glucose, (, 0.4mM]</td>\n",
       "      <td>[27*#*28, 12*#*17, 5*#*10, 30*#*36]</td>\n",
       "      <td>[11*#*12, 3*#*4, 29*#*30]</td>\n",
       "      <td>{'5*#*10': 'alpha-D-glucose', '12*#*17': 'alph...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>alpha-D-xylose</td>\n",
       "      <td>25mM</td>\n",
       "      <td>[12, 17]</td>\n",
       "      <td>[29, 30]</td>\n",
       "      <td>As  as 0.2mM added alpha-D-glucose (0.4mM alph...</td>\n",
       "      <td>[As,  , as, 0.2mM, added, alpha, -, D, -, gluc...</td>\n",
       "      <td>[),  , increased, the, rate, of, enzymically, ...</td>\n",
       "      <td>[27*#*28, 12*#*17, 5*#*10, 30*#*36]</td>\n",
       "      <td>[11*#*12, 3*#*4, 29*#*30]</td>\n",
       "      <td>{'5*#*10': 'alpha-D-glucose', '12*#*17': 'alph...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fluoride</td>\n",
       "      <td>0.2mM</td>\n",
       "      <td>[27, 28]</td>\n",
       "      <td>[3, 4]</td>\n",
       "      <td>As  as 0.2mM added alpha-D-glucose (0.4mM alph...</td>\n",
       "      <td>[As,  , as, 0.2mM, added, alpha, -, D, -, gluc...</td>\n",
       "      <td>[added, alpha, -, D, -, glucose, (, 0.4mM, alp...</td>\n",
       "      <td>[27*#*28, 12*#*17, 5*#*10, 30*#*36]</td>\n",
       "      <td>[11*#*12, 3*#*4, 29*#*30]</td>\n",
       "      <td>{'5*#*10': 'alpha-D-glucose', '12*#*17': 'alph...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         chem_word prod_word chem_word_idx prod_word_idx  \\\n",
       "0  alpha-D-glucose     0.2mM       [5, 10]        [3, 4]   \n",
       "1  alpha-D-glucose      25mM       [5, 10]      [29, 30]   \n",
       "2   alpha-D-xylose     0.2mM      [12, 17]        [3, 4]   \n",
       "3   alpha-D-xylose      25mM      [12, 17]      [29, 30]   \n",
       "4         fluoride     0.2mM      [27, 28]        [3, 4]   \n",
       "\n",
       "                                            sentence  \\\n",
       "0  As  as 0.2mM added alpha-D-glucose (0.4mM alph...   \n",
       "1  As  as 0.2mM added alpha-D-glucose (0.4mM alph...   \n",
       "2  As  as 0.2mM added alpha-D-glucose (0.4mM alph...   \n",
       "3  As  as 0.2mM added alpha-D-glucose (0.4mM alph...   \n",
       "4  As  as 0.2mM added alpha-D-glucose (0.4mM alph...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [As,  , as, 0.2mM, added, alpha, -, D, -, gluc...   \n",
       "1  [As,  , as, 0.2mM, added, alpha, -, D, -, gluc...   \n",
       "2  [As,  , as, 0.2mM, added, alpha, -, D, -, gluc...   \n",
       "3  [As,  , as, 0.2mM, added, alpha, -, D, -, gluc...   \n",
       "4  [As,  , as, 0.2mM, added, alpha, -, D, -, gluc...   \n",
       "\n",
       "                                      between_tokens  \\\n",
       "0                                            [added]   \n",
       "1  [(, 0.4mM, alpha, -, D, -, xylose, ),  , incre...   \n",
       "2         [added, alpha, -, D, -, glucose, (, 0.4mM]   \n",
       "3  [),  , increased, the, rate, of, enzymically, ...   \n",
       "4  [added, alpha, -, D, -, glucose, (, 0.4mM, alp...   \n",
       "\n",
       "                                 chems                      prods  \\\n",
       "0  [27*#*28, 12*#*17, 5*#*10, 30*#*36]  [11*#*12, 3*#*4, 29*#*30]   \n",
       "1  [27*#*28, 12*#*17, 5*#*10, 30*#*36]  [11*#*12, 3*#*4, 29*#*30]   \n",
       "2  [27*#*28, 12*#*17, 5*#*10, 30*#*36]  [11*#*12, 3*#*4, 29*#*30]   \n",
       "3  [27*#*28, 12*#*17, 5*#*10, 30*#*36]  [11*#*12, 3*#*4, 29*#*30]   \n",
       "4  [27*#*28, 12*#*17, 5*#*10, 30*#*36]  [11*#*12, 3*#*4, 29*#*30]   \n",
       "\n",
       "                                       chem_pos_word label  \n",
       "0  {'5*#*10': 'alpha-D-glucose', '12*#*17': 'alph...    -1  \n",
       "1  {'5*#*10': 'alpha-D-glucose', '12*#*17': 'alph...    -1  \n",
       "2  {'5*#*10': 'alpha-D-glucose', '12*#*17': 'alph...    -1  \n",
       "3  {'5*#*10': 'alpha-D-glucose', '12*#*17': 'alph...    -1  \n",
       "4  {'5*#*10': 'alpha-D-glucose', '12*#*17': 'alph...    -1  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "df_dev=pd.read_pickle(\"../ProcessedData/procon_corpus.pkl\")\n",
    "df_dev=df_dev.loc[:,\"chem_word\":\"label\"]\n",
    "df_dev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chem_word</th>\n",
       "      <th>prod_word</th>\n",
       "      <th>chem_word_idx</th>\n",
       "      <th>prod_word_idx</th>\n",
       "      <th>sentence</th>\n",
       "      <th>tokens</th>\n",
       "      <th>between_tokens</th>\n",
       "      <th>chems</th>\n",
       "      <th>prods</th>\n",
       "      <th>chem_pos_word</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>icariside D2</td>\n",
       "      <td>3.80 g/L</td>\n",
       "      <td>[22, 24]</td>\n",
       "      <td>[17, 21]</td>\n",
       "      <td>Under the optimal conditions in fed-batch shak...</td>\n",
       "      <td>[Under, the, optimal, conditions, in, fed, -, ...</td>\n",
       "      <td>[of]</td>\n",
       "      <td>[25*#*26, 41*#*43, 44*#*47, 28*#*29, 22*#*24]</td>\n",
       "      <td>[36*#*40, 17*#*21]</td>\n",
       "      <td>{'22*#*24': 'icariside D2', '41*#*43': 'icaris...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>icariside D2</td>\n",
       "      <td>2.92 g/L</td>\n",
       "      <td>[41, 43]</td>\n",
       "      <td>[36, 40]</td>\n",
       "      <td>Under the optimal conditions in fed-batch shak...</td>\n",
       "      <td>[Under, the, optimal, conditions, in, fed, -, ...</td>\n",
       "      <td>[of]</td>\n",
       "      <td>[25*#*26, 41*#*43, 44*#*47, 28*#*29, 22*#*24]</td>\n",
       "      <td>[36*#*40, 17*#*21]</td>\n",
       "      <td>{'22*#*24': 'icariside D2', '41*#*43': 'icaris...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>icariside D2</td>\n",
       "      <td>2.92 g/L</td>\n",
       "      <td>[22, 24]</td>\n",
       "      <td>[36, 40]</td>\n",
       "      <td>Under the optimal conditions in fed-batch shak...</td>\n",
       "      <td>[Under, the, optimal, conditions, in, fed, -, ...</td>\n",
       "      <td>[using, glucose, as, sole, carbon, source, ,, ...</td>\n",
       "      <td>[25*#*26, 41*#*43, 44*#*47, 28*#*29, 22*#*24]</td>\n",
       "      <td>[36*#*40, 17*#*21]</td>\n",
       "      <td>{'22*#*24': 'icariside D2', '41*#*43': 'icaris...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>glucose</td>\n",
       "      <td>3.80 g/L</td>\n",
       "      <td>[25, 26]</td>\n",
       "      <td>[17, 21]</td>\n",
       "      <td>Under the optimal conditions in fed-batch shak...</td>\n",
       "      <td>[Under, the, optimal, conditions, in, fed, -, ...</td>\n",
       "      <td>[of, icariside, D2, using]</td>\n",
       "      <td>[25*#*26, 41*#*43, 44*#*47, 28*#*29, 22*#*24]</td>\n",
       "      <td>[36*#*40, 17*#*21]</td>\n",
       "      <td>{'22*#*24': 'icariside D2', '41*#*43': 'icaris...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>glucose</td>\n",
       "      <td>2.92 g/L</td>\n",
       "      <td>[25, 26]</td>\n",
       "      <td>[36, 40]</td>\n",
       "      <td>Under the optimal conditions in fed-batch shak...</td>\n",
       "      <td>[Under, the, optimal, conditions, in, fed, -, ...</td>\n",
       "      <td>[as, sole, carbon, source, ,, and, the, BMT23-...</td>\n",
       "      <td>[25*#*26, 41*#*43, 44*#*47, 28*#*29, 22*#*24]</td>\n",
       "      <td>[36*#*40, 17*#*21]</td>\n",
       "      <td>{'22*#*24': 'icariside D2', '41*#*43': 'icaris...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      chem_word prod_word chem_word_idx prod_word_idx  \\\n",
       "0  icariside D2  3.80 g/L      [22, 24]      [17, 21]   \n",
       "1  icariside D2  2.92 g/L      [41, 43]      [36, 40]   \n",
       "2  icariside D2  2.92 g/L      [22, 24]      [36, 40]   \n",
       "3       glucose  3.80 g/L      [25, 26]      [17, 21]   \n",
       "4       glucose  2.92 g/L      [25, 26]      [36, 40]   \n",
       "\n",
       "                                            sentence  \\\n",
       "0  Under the optimal conditions in fed-batch shak...   \n",
       "1  Under the optimal conditions in fed-batch shak...   \n",
       "2  Under the optimal conditions in fed-batch shak...   \n",
       "3  Under the optimal conditions in fed-batch shak...   \n",
       "4  Under the optimal conditions in fed-batch shak...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [Under, the, optimal, conditions, in, fed, -, ...   \n",
       "1  [Under, the, optimal, conditions, in, fed, -, ...   \n",
       "2  [Under, the, optimal, conditions, in, fed, -, ...   \n",
       "3  [Under, the, optimal, conditions, in, fed, -, ...   \n",
       "4  [Under, the, optimal, conditions, in, fed, -, ...   \n",
       "\n",
       "                                      between_tokens  \\\n",
       "0                                               [of]   \n",
       "1                                               [of]   \n",
       "2  [using, glucose, as, sole, carbon, source, ,, ...   \n",
       "3                         [of, icariside, D2, using]   \n",
       "4  [as, sole, carbon, source, ,, and, the, BMT23-...   \n",
       "\n",
       "                                           chems               prods  \\\n",
       "0  [25*#*26, 41*#*43, 44*#*47, 28*#*29, 22*#*24]  [36*#*40, 17*#*21]   \n",
       "1  [25*#*26, 41*#*43, 44*#*47, 28*#*29, 22*#*24]  [36*#*40, 17*#*21]   \n",
       "2  [25*#*26, 41*#*43, 44*#*47, 28*#*29, 22*#*24]  [36*#*40, 17*#*21]   \n",
       "3  [25*#*26, 41*#*43, 44*#*47, 28*#*29, 22*#*24]  [36*#*40, 17*#*21]   \n",
       "4  [25*#*26, 41*#*43, 44*#*47, 28*#*29, 22*#*24]  [36*#*40, 17*#*21]   \n",
       "\n",
       "                                       chem_pos_word label  \n",
       "0  {'22*#*24': 'icariside D2', '41*#*43': 'icaris...     1  \n",
       "1  {'22*#*24': 'icariside D2', '41*#*43': 'icaris...     1  \n",
       "2  {'22*#*24': 'icariside D2', '41*#*43': 'icaris...    -1  \n",
       "3  {'22*#*24': 'icariside D2', '41*#*43': 'icaris...    -1  \n",
       "4  {'22*#*24': 'icariside D2', '41*#*43': 'icaris...    -1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df_train = pd.read_pickle(\"../ProcessedData/train_corpus.pkl\")\n",
    "df_train = df_train.loc[:,\"chem_word\":\"label\"]\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat = pd.concat([df_dev, df_train], axis=0)\n",
    "df_concat = df_concat.reset_index(drop=True)\n",
    "df_concat.to_pickle(\"../ProcessedData/train_procon_corpus.pkl\")  #2063"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chem_word</th>\n",
       "      <th>prod_word</th>\n",
       "      <th>chem_word_idx</th>\n",
       "      <th>prod_word_idx</th>\n",
       "      <th>sentence</th>\n",
       "      <th>tokens</th>\n",
       "      <th>between_tokens</th>\n",
       "      <th>chems</th>\n",
       "      <th>prods</th>\n",
       "      <th>chem_pos_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alpha-D-glucose</td>\n",
       "      <td>0.2mM</td>\n",
       "      <td>[5, 10]</td>\n",
       "      <td>[3, 4]</td>\n",
       "      <td>As  as 0.2mM added alpha-D-glucose (0.4mM alph...</td>\n",
       "      <td>[As,  , as, 0.2mM, added, alpha, -, D, -, gluc...</td>\n",
       "      <td>[added]</td>\n",
       "      <td>[27*#*28, 12*#*17, 5*#*10, 30*#*36]</td>\n",
       "      <td>[11*#*12, 3*#*4, 29*#*30]</td>\n",
       "      <td>{'5*#*10': 'alpha-D-glucose', '12*#*17': 'alph...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alpha-D-glucose</td>\n",
       "      <td>25mM</td>\n",
       "      <td>[5, 10]</td>\n",
       "      <td>[29, 30]</td>\n",
       "      <td>As  as 0.2mM added alpha-D-glucose (0.4mM alph...</td>\n",
       "      <td>[As,  , as, 0.2mM, added, alpha, -, D, -, gluc...</td>\n",
       "      <td>[(, 0.4mM, alpha, -, D, -, xylose, ),  , incre...</td>\n",
       "      <td>[27*#*28, 12*#*17, 5*#*10, 30*#*36]</td>\n",
       "      <td>[11*#*12, 3*#*4, 29*#*30]</td>\n",
       "      <td>{'5*#*10': 'alpha-D-glucose', '12*#*17': 'alph...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>alpha-D-xylose</td>\n",
       "      <td>0.2mM</td>\n",
       "      <td>[12, 17]</td>\n",
       "      <td>[3, 4]</td>\n",
       "      <td>As  as 0.2mM added alpha-D-glucose (0.4mM alph...</td>\n",
       "      <td>[As,  , as, 0.2mM, added, alpha, -, D, -, gluc...</td>\n",
       "      <td>[added, alpha, -, D, -, glucose, (, 0.4mM]</td>\n",
       "      <td>[27*#*28, 12*#*17, 5*#*10, 30*#*36]</td>\n",
       "      <td>[11*#*12, 3*#*4, 29*#*30]</td>\n",
       "      <td>{'5*#*10': 'alpha-D-glucose', '12*#*17': 'alph...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>alpha-D-xylose</td>\n",
       "      <td>25mM</td>\n",
       "      <td>[12, 17]</td>\n",
       "      <td>[29, 30]</td>\n",
       "      <td>As  as 0.2mM added alpha-D-glucose (0.4mM alph...</td>\n",
       "      <td>[As,  , as, 0.2mM, added, alpha, -, D, -, gluc...</td>\n",
       "      <td>[),  , increased, the, rate, of, enzymically, ...</td>\n",
       "      <td>[27*#*28, 12*#*17, 5*#*10, 30*#*36]</td>\n",
       "      <td>[11*#*12, 3*#*4, 29*#*30]</td>\n",
       "      <td>{'5*#*10': 'alpha-D-glucose', '12*#*17': 'alph...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fluoride</td>\n",
       "      <td>0.2mM</td>\n",
       "      <td>[27, 28]</td>\n",
       "      <td>[3, 4]</td>\n",
       "      <td>As  as 0.2mM added alpha-D-glucose (0.4mM alph...</td>\n",
       "      <td>[As,  , as, 0.2mM, added, alpha, -, D, -, gluc...</td>\n",
       "      <td>[added, alpha, -, D, -, glucose, (, 0.4mM, alp...</td>\n",
       "      <td>[27*#*28, 12*#*17, 5*#*10, 30*#*36]</td>\n",
       "      <td>[11*#*12, 3*#*4, 29*#*30]</td>\n",
       "      <td>{'5*#*10': 'alpha-D-glucose', '12*#*17': 'alph...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         chem_word prod_word chem_word_idx prod_word_idx  \\\n",
       "0  alpha-D-glucose     0.2mM       [5, 10]        [3, 4]   \n",
       "1  alpha-D-glucose      25mM       [5, 10]      [29, 30]   \n",
       "2   alpha-D-xylose     0.2mM      [12, 17]        [3, 4]   \n",
       "3   alpha-D-xylose      25mM      [12, 17]      [29, 30]   \n",
       "4         fluoride     0.2mM      [27, 28]        [3, 4]   \n",
       "\n",
       "                                            sentence  \\\n",
       "0  As  as 0.2mM added alpha-D-glucose (0.4mM alph...   \n",
       "1  As  as 0.2mM added alpha-D-glucose (0.4mM alph...   \n",
       "2  As  as 0.2mM added alpha-D-glucose (0.4mM alph...   \n",
       "3  As  as 0.2mM added alpha-D-glucose (0.4mM alph...   \n",
       "4  As  as 0.2mM added alpha-D-glucose (0.4mM alph...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [As,  , as, 0.2mM, added, alpha, -, D, -, gluc...   \n",
       "1  [As,  , as, 0.2mM, added, alpha, -, D, -, gluc...   \n",
       "2  [As,  , as, 0.2mM, added, alpha, -, D, -, gluc...   \n",
       "3  [As,  , as, 0.2mM, added, alpha, -, D, -, gluc...   \n",
       "4  [As,  , as, 0.2mM, added, alpha, -, D, -, gluc...   \n",
       "\n",
       "                                      between_tokens  \\\n",
       "0                                            [added]   \n",
       "1  [(, 0.4mM, alpha, -, D, -, xylose, ),  , incre...   \n",
       "2         [added, alpha, -, D, -, glucose, (, 0.4mM]   \n",
       "3  [),  , increased, the, rate, of, enzymically, ...   \n",
       "4  [added, alpha, -, D, -, glucose, (, 0.4mM, alp...   \n",
       "\n",
       "                                 chems                      prods  \\\n",
       "0  [27*#*28, 12*#*17, 5*#*10, 30*#*36]  [11*#*12, 3*#*4, 29*#*30]   \n",
       "1  [27*#*28, 12*#*17, 5*#*10, 30*#*36]  [11*#*12, 3*#*4, 29*#*30]   \n",
       "2  [27*#*28, 12*#*17, 5*#*10, 30*#*36]  [11*#*12, 3*#*4, 29*#*30]   \n",
       "3  [27*#*28, 12*#*17, 5*#*10, 30*#*36]  [11*#*12, 3*#*4, 29*#*30]   \n",
       "4  [27*#*28, 12*#*17, 5*#*10, 30*#*36]  [11*#*12, 3*#*4, 29*#*30]   \n",
       "\n",
       "                                       chem_pos_word  \n",
       "0  {'5*#*10': 'alpha-D-glucose', '12*#*17': 'alph...  \n",
       "1  {'5*#*10': 'alpha-D-glucose', '12*#*17': 'alph...  \n",
       "2  {'5*#*10': 'alpha-D-glucose', '12*#*17': 'alph...  \n",
       "3  {'5*#*10': 'alpha-D-glucose', '12*#*17': 'alph...  \n",
       "4  {'5*#*10': 'alpha-D-glucose', '12*#*17': 'alph...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "treenlp = spacy.load(\"en_core_web_sm\")\n",
    "df_dev=pd.read_pickle(\"../ProcessedData/train_procon_corpus.pkl\")\n",
    "new_df_dev = df_dev[\"label\"]\n",
    "labels = [1 if i == 1 else 0 for i in new_df_dev]\n",
    "Y_dev = np.array(labels)\n",
    "df_dev=df_dev.loc[:,\"chem_word\":\"chem_pos_word\"]\n",
    "df_dev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2063, 10)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_lable(cand): \n",
    "    tokens = cand.tokens \n",
    "    sentence_positive_tokens =  {\"batch\",\"pathway\",'fermentation','production','engineer','yield','titer',\\\n",
    "                  'biosynthesis','synthesis','flask','heterologous','titre','yields','concentration','incubation',\\\n",
    "                 'metabolic','novo','coli','accumulation','conversion','converted','productivity','metabolites',\\\n",
    "                 'productivities','quantities','produced','convert','flasks','laboratory','Yields','growth',\\\n",
    "                 'reaching','detected','content','concentrations','reached','synthesized','producing','accumulated',\\\n",
    "                 'resulting','accumulate','fermenter','contents','titers','rate','biotransformation','produces',\\\n",
    "                                'Increasing','enhances','produces'}\n",
    "    if len(sentence_positive_tokens.intersection(set(tokens)))>0:\n",
    "        lable = 1\n",
    "    else:\n",
    "        lable = 0\n",
    "    return lable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "POSITIVE = 1\n",
    "NEGATIVE = 0\n",
    "ABSTAIN = -1\n",
    "def get_pos_in_order(chemprod_list):\n",
    "    \"\"\"\n",
    "    #input = [11*#*14, 20*#*21, 27*#*28, 9*#*10, 34*#*35]\n",
    "    #output = [[9, 10], [11, 14], [20, 21], [27, 28], [34, 35]]\n",
    "    \"\"\"\n",
    "    chemprod_pos_list = [[int(chemprod_pos) for chemprod_pos in chemprod.split(\"*#*\")] \\\n",
    "                         for chemprod in chemprod_list]\n",
    "    chemprod_pos_order_list = (sorted(chemprod_pos_list, key=lambda k: k[0]))\n",
    "    return chemprod_pos_order_list\n",
    "\n",
    "def get_prod_chem_span(x):\n",
    "    \"\"\"\n",
    "    prod_left,prod_right,chem_left,chem_right\n",
    "    span_pos = [prod_left,chem_right]\n",
    "    \"\"\"\n",
    "    chems = x.chems\n",
    "    prods = x.prods\n",
    "    ProdChemBetweenOne = {'of',')','-'}\n",
    "    chem_pos_order = get_pos_in_order(chems)\n",
    "    prod_pos_order = get_pos_in_order(prods)\n",
    "    \n",
    "    #print(chem_pos_order,prod_pos_order)\n",
    "    prod_chem_spans = []\n",
    "    prod_chem_span_left_edge = {}\n",
    "    prod_chem_span_right_edge = {}\n",
    "    for prod_pos in prod_pos_order:\n",
    "        prod_left ,prod_right = prod_pos\n",
    "        for chem_pos in chem_pos_order:\n",
    "            chem_left,chem_right = chem_pos\n",
    "            chem_pos_diff = chem_left - prod_right\n",
    "            if chem_pos_diff <0:\n",
    "                continue\n",
    "            elif chem_pos_diff == 0:\n",
    "                prod_chem = [prod_left,chem_right]\n",
    "                prod_chem_spans.append(prod_chem)\n",
    "                prod_chem_span_right_edge[prod_left] = chem_right\n",
    "                prod_chem_span_left_edge[chem_right] = prod_left\n",
    "                break\n",
    "            elif chem_pos_diff == 1: \n",
    "                between_tokens = x.tokens[prod_right:chem_left]\n",
    "                if len(ProdChemBetweenOne.intersection(set(between_tokens))) > 0:\n",
    "                    prod_chem = [prod_left,chem_right]\n",
    "                    prod_chem_spans.append(prod_chem)\n",
    "                    prod_chem_span_right_edge[prod_left] = chem_right\n",
    "                    prod_chem_span_left_edge[chem_right] = prod_left                    \n",
    "                    break\n",
    "            else:\n",
    "                break\n",
    "    return prod_chem_spans,prod_chem_span_left_edge,prod_chem_span_right_edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clear_prodpos_chemtext(x):\n",
    "    chems = x.chems\n",
    "    prods = x.prods\n",
    "    chem_pos_word = x.chem_pos_word\n",
    "    ProdChemBetweenOne = {'of',')','-'}\n",
    "    chem_pos_order = get_pos_in_order(chems)\n",
    "    prod_pos_order = get_pos_in_order(prods)\n",
    "    #input = [11*#*14, 20*#*21, 27*#*28, 9*#*10, 34*#*35]\n",
    "    #output = [[9, 10], [11, 14], [20, 21], [27, 28], [34, 35]]    \n",
    "    prodpos_chemtext = {}\n",
    "    for prod_pos in prod_pos_order:\n",
    "        prod_left ,prod_right = prod_pos\n",
    "        for chem_pos in chem_pos_order:\n",
    "            chem_left,chem_right = chem_pos\n",
    "            chem_pos_diff = chem_left - prod_right\n",
    "            if chem_pos_diff <0:\n",
    "                continue\n",
    "            elif chem_pos_diff == 0:\n",
    "                prod_clear_pos = prod_pos\n",
    "                prod_pos = \"{}*#*{}\".format(prod_left ,prod_right)\n",
    "                chem_pos = \"{}*#*{}\".format(chem_left,chem_right)\n",
    "                chem_clear_text = chem_pos_word[chem_pos]\n",
    "                prodpos_chemtext[prod_pos] = chem_clear_text\n",
    "            elif chem_pos_diff == 1:\n",
    "                between_tokens = x.tokens[prod_right:chem_left]\n",
    "                if len(ProdChemBetweenOne.intersection(set(between_tokens))) > 0:\n",
    "                    prod_pos = \"{}*#*{}\".format(prod_left ,prod_right)\n",
    "                    \n",
    "                    prod_clear_pos = prod_pos\n",
    "                    chem_pos = \"{}*#*{}\".format(chem_left,chem_right)\n",
    "                    chem_clear_text = chem_pos_word[chem_pos]\n",
    "                    #print(\"prod_pos\",prod_pos,chem_clear_text)\n",
    "                    prodpos_chemtext[prod_pos] = chem_clear_text  \n",
    "            else:\n",
    "                break\n",
    "    chem_prod_between_tokens = {'(','of','concentration','concentrations','were','was',',',';'}\n",
    "    for prod_pos in prod_pos_order:\n",
    "        prod_left ,prod_right = prod_pos\n",
    "        for chem_pos in chem_pos_order:\n",
    "            chem_left,chem_right = chem_pos\n",
    "            chem_pos_diff = prod_left - chem_right\n",
    "            #print(\"3\"*30,chem_pos_diff)\n",
    "            \n",
    "            if chem_pos_diff >2:\n",
    "                \n",
    "                continue\n",
    "            elif chem_pos_diff == 0:\n",
    "                \n",
    "                prod_clear_pos = prod_pos\n",
    "                prod_pos = \"{}*#*{}\".format(prod_left ,prod_right)\n",
    "                chem_pos = \"{}*#*{}\".format(chem_left,chem_right)\n",
    "                chem_clear_text = chem_pos_word[chem_pos]\n",
    "                prodpos_chemtext[prod_pos] = chem_clear_text\n",
    "            elif chem_pos_diff == 1:\n",
    "                between_tokens = x.tokens[chem_right:prod_left]\n",
    "                if len(chem_prod_between_tokens.intersection(set(between_tokens))) > 0:\n",
    "                    prod_clear_pos = prod_pos\n",
    "                    prod_pos = \"{}*#*{}\".format(prod_left ,prod_right)\n",
    "                    chem_pos = \"{}*#*{}\".format(chem_left,chem_right)\n",
    "                    chem_clear_text = chem_pos_word[chem_pos]\n",
    "                    #print(\"prod_pos\",prod_pos,chem_clear_text)\n",
    "                    prodpos_chemtext[prod_pos] = chem_clear_text\n",
    "            elif chem_pos_diff == 2:\n",
    "                \n",
    "                \n",
    "                between_tokens = x.tokens[chem_right:prod_left]\n",
    "                #print(\"3\"*30,between_tokens)\n",
    "                if len(chem_prod_between_tokens.intersection(set(between_tokens))) > 1:\n",
    "                    prod_clear_pos = prod_pos\n",
    "                    prod_pos = \"{}*#*{}\".format(prod_left ,prod_right)\n",
    "                    chem_pos = \"{}*#*{}\".format(chem_left,chem_right)\n",
    "                    chem_clear_text = chem_pos_word[chem_pos]\n",
    "                    prodpos_chemtext[prod_pos] = chem_clear_text                   \n",
    "\n",
    "    return prodpos_chemtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_multiple_prod_chem_span(x):\n",
    "    chunck_labels = {'and'}\n",
    "    prod_chem_spans,_left,_right = get_prod_chem_span(x)\n",
    "    #print(prod_chem_spans,_left,_right)\n",
    "    multiple_prod_chem_span = {}\n",
    "    span_length = len(prod_chem_spans)\n",
    "    if span_length<1:\n",
    "        return multiple_prod_chem_span\n",
    "    else:\n",
    "        for i in range(span_length-1):\n",
    "            span_left = prod_chem_spans[i][1]\n",
    "            span_right = prod_chem_spans[i+1][0]\n",
    "            #print(span_left,span_right)\n",
    "            span_diff = span_right- span_left\n",
    "            if span_diff == 1:\n",
    "                span_tokens = x.tokens[span_left:span_right]\n",
    "                if len(chunck_labels.intersection(set(span_tokens))) > 0:\n",
    "                    span_left = prod_chem_spans[i][0]\n",
    "                    span_right = prod_chem_spans[i+1][1]\n",
    "                    multiple_prod_chem_span[span_right] = span_left\n",
    "    return multiple_prod_chem_span,_left,_right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chem_left_edge(x,chem_word_idx):\n",
    "    chem_left,chem_right = chem_word_idx\n",
    "    chem_left_pos_dict = get_multiple_prod_chem_span(x)\n",
    "    if chem_left_pos_dict:\n",
    "        chem_left_edge = min([sub_dict.get(chem_right,chem_left)  for sub_dict in chem_left_pos_dict])\n",
    "    else:\n",
    "        chem_left_edge = chem_left\n",
    "    \n",
    "    return chem_left_edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def left_right_tokens_prod(prod_word_idx,tokens,window):\n",
    "    prod_word_left,prod_word_right = prod_word_idx\n",
    "    #tokens = cand.tokens\n",
    "    #window = 2\n",
    "    prod_left_token = tokens[0:prod_word_left+1][-1 - window : -1]\n",
    "    prod_right_token = tokens[prod_word_right:][0 : window]\n",
    "\n",
    "    return prod_left_token,prod_right_token\n",
    "\n",
    "    \n",
    "def left_right_tokens_chem(chem_word_idx,tokens,window):\n",
    "    chem_word_left,chem_word_right = chem_word_idx\n",
    "    #tokens = cand.tokens\n",
    "    #window = 2\n",
    "\n",
    "    chem_left_token = tokens[0:chem_word_left+1][-1 - window : -1]\n",
    "    chem_right_token = tokens[chem_word_right:][0 : window]\n",
    "\n",
    "    return chem_left_token,chem_right_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict,defaultdict\n",
    "def get_multiple_spans(chem_word_poss,tokens):\n",
    "    \"\"\"\n",
    "    cluster serial numbers\n",
    "    initial_dict={33: 35, 58: 59, 60: 63, 15: 16}\n",
    "    result = [[(58, 59), (60, 63)]]\n",
    "    \n",
    "    \"\"\"\n",
    "    chem_pos_dig = {}\n",
    "    #print(\"chem_word_poss\",chem_word_poss)\n",
    "    for chem_word_pos in chem_word_poss:\n",
    "        #print()\n",
    "        chem_word_start,chem_word_end = chem_word_pos.split(\"*#*\")\n",
    "        chem_start_dig = int(chem_word_start)\n",
    "        chem_end_dig = int(chem_word_end)\n",
    "        #chem_start_dig = get_chem_left_edge(x,[chem_start_dig,chem_end_dig])\n",
    "        chem_pos_dig[chem_start_dig] = chem_end_dig\n",
    "    #print(chem_pos_dig)\n",
    "\n",
    "    new_chem_pos = OrderedDict(sorted(chem_pos_dig.items()))\n",
    "    #print('new_chem_pos',new_chem_pos)\n",
    "    label = 0\n",
    "    record_pos_dict = defaultdict(list)\n",
    "    \n",
    "    for _start , _end in new_chem_pos.items():\n",
    "        chem_left_tokens,chem_right_tokens = left_right_tokens_prod((_start , _end),tokens,window=1)\n",
    "        #print(chem_left_tokens,chem_right_tokens)\n",
    "        \n",
    "        if label == 0:            \n",
    "            label +=1\n",
    "            tmp_end = _end\n",
    "        if \"from\" in chem_left_tokens:\n",
    "            label += 1\n",
    "        elif \"mol\" in chem_left_tokens:\n",
    "            label += 1            \n",
    "        if _start - tmp_end >2:\n",
    "            label +=1            \n",
    "        record_pos_dict[label].append(_start)\n",
    "        tmp_end = _end    \n",
    "    #print('record_pos_dict',record_pos_dict)\n",
    "    mutipl_spans = []\n",
    "    for dig_label,dig_start in record_pos_dict.items():\n",
    "        if len(dig_start)>1:\n",
    "            mutipl_span = []\n",
    "            for _dig_start in dig_start:\n",
    "                _dig_end = chem_pos_dig[_dig_start]\n",
    "                dig_start_end = (_dig_start,_dig_end)\n",
    "                dig_start_end_text = '{}*#*{}'.format(_dig_start,_dig_end)\n",
    "                mutipl_span.append(dig_start_end_text)\n",
    "                #print(_dig_start,_dig_end)\n",
    "            mutipl_spans.append(mutipl_span)\n",
    "    #print(\"mutipl_spans\",\"*\"*20,mutipl_spans)\n",
    "    return mutipl_spans\n",
    "\n",
    "from snorkel.types import DataPoint\n",
    "from snorkel.preprocess import preprocessor\n",
    "@preprocessor()\n",
    "def get_chemnum_between_prod_chem(cand):\n",
    "    \"\"\"\n",
    "    Returns the chems num between prod and chem\n",
    "    \"\"\"\n",
    "    chem_word_idx = cand.chem_word_idx\n",
    "    prod_word_idx = cand.prod_word_idx\n",
    "    chem_start = chem_word_idx[0]\n",
    "    chem_end = chem_word_idx[1]\n",
    "    prod_start = prod_word_idx[0]\n",
    "    prod_end = prod_word_idx[1]\n",
    "    between_chemnum = 0    \n",
    "    if chem_end < prod_end:\n",
    "        between_chemnum += 1\n",
    "        prod_chem_order = False\n",
    "        cand.between_prod_chem_chemnum = between_chemnum\n",
    "        cand.prod_chem_order = prod_chem_order        \n",
    "        return cand\n",
    "\n",
    "    else:\n",
    "        prod_chem_order = True\n",
    "        left = prod_end\n",
    "        right = chem_start\n",
    "    prod_chem_nums = [i for i in range(left,right)]\n",
    "    \n",
    "    chem_pos_text = \"{}*#*{}\".format(chem_word_idx[0],chem_word_idx[1])\n",
    "    cand_chems = cand.chems\n",
    "    #print(cand_chems)\n",
    "    cand_spans = get_multiple_spans(cand_chems,cand.tokens)\n",
    "    cand_span_pos_newpos = {}\n",
    "    for cand_span in cand_spans:\n",
    "        for i in range(1,len(cand_span)):\n",
    "            cand_span_pos_newpos[cand_span[i]] = cand_span[0] \n",
    "    #print(cand_span_pos_newpos)\n",
    "    for _chem in cand.chems:\n",
    "        if _chem in cand_span_pos_newpos.keys():\n",
    "            _chem = cand_span_pos_newpos[_chem]\n",
    "        chem_left = _chem.split(\"*#*\")[0]\n",
    "        if int(chem_left) in prod_chem_nums:\n",
    "            between_chemnum += 1\n",
    "    cand.between_prod_chem_chemnum = between_chemnum\n",
    "    \n",
    "    cand.prod_chem_order = prod_chem_order\n",
    "    return cand "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict,defaultdict\n",
    "def get_multiple_prod_chem_spans(x,chem_word_poss,tokens):\n",
    "    \"\"\"\n",
    "    cluster serial numbers\n",
    "    initial_dict={33: 35, 58: 59, 60: 63, 15: 16}\n",
    "    result = [[(58, 59), (60, 63)]]\n",
    "    \n",
    "    \"\"\"\n",
    "    chem_pos_dig = {}\n",
    "    #print(\"chem_word_poss\",chem_word_poss)\n",
    "    for chem_word_pos in chem_word_poss:\n",
    "        #print()\n",
    "        chem_word_start,chem_word_end = chem_word_pos.split(\"*#*\")\n",
    "        chem_start_dig = int(chem_word_start)\n",
    "        chem_end_dig = int(chem_word_end)\n",
    "        chem_start_dig = get_chem_left_edge(x,[chem_start_dig,chem_end_dig])\n",
    "        chem_pos_dig[chem_start_dig] = chem_end_dig\n",
    "    #print(chem_pos_dig)\n",
    "\n",
    "    new_chem_pos = OrderedDict(sorted(chem_pos_dig.items()))\n",
    "    #print('new_chem_pos',new_chem_pos)\n",
    "    label = 0\n",
    "    record_pos_dict = defaultdict(list)\n",
    "    \n",
    "    for _start , _end in new_chem_pos.items():\n",
    "        chem_left_tokens,chem_right_tokens = left_right_tokens_prod((_start , _end),tokens,window=1)\n",
    "        #print(chem_left_tokens,chem_right_tokens)\n",
    "        \n",
    "        if label == 0:            \n",
    "            label +=1\n",
    "            tmp_end = _end\n",
    "        if \"from\" in chem_left_tokens:\n",
    "            label += 1\n",
    "        elif \"mol\" in chem_left_tokens:\n",
    "            label += 1            \n",
    "        if _start - tmp_end >2:\n",
    "            label +=1            \n",
    "        record_pos_dict[label].append(_start)\n",
    "        tmp_end = _end    \n",
    "    #print('record_pos_dict',record_pos_dict)\n",
    "    mutipl_spans = []\n",
    "    for dig_label,dig_start in record_pos_dict.items():\n",
    "        if len(dig_start)>1:\n",
    "            mutipl_span = []\n",
    "            for _dig_start in dig_start:\n",
    "                _dig_end = chem_pos_dig[_dig_start]\n",
    "                dig_start_end = (_dig_start,_dig_end)\n",
    "                dig_start_end_text = '{}*#*{}'.format(_dig_start,_dig_end)\n",
    "                mutipl_span.append(dig_start_end_text)\n",
    "                #print(_dig_start,_dig_end)\n",
    "            mutipl_spans.append(mutipl_span)\n",
    "    #print(\"mutipl_spans\",\"*\"*20,mutipl_spans)\n",
    "    return mutipl_spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "def get_negtive_tokens_index(cand):\n",
    "    sentence = cand.sentence\n",
    "    #print(sentence)\n",
    "    tokens = negtivenlp(sentence)\n",
    "    tokens_len = len(tokens)\n",
    "    tokens_index = [tok.i for tok in tokens if tok.pos_=='VERB']\n",
    "    tokens_index.append(tokens_len)\n",
    "    #print(tokens_index)\n",
    "    negtive_start = tokens_len\n",
    "    negtive_end = tokens_len\n",
    "    for token in tokens:\n",
    "        try:\n",
    "            left_neigbor = token.nbor(-1)\n",
    "        except:\n",
    "            left_neigbor = token\n",
    "        token_text = token.text\n",
    "        token_pos = token.pos_\n",
    "        left_token_text = left_neigbor.text\n",
    "        token_index = token.i  \n",
    "        #print(token.text,\"-->\",token.pos_,\"-->\",token.i,\"-->\",left_neigbor.text)\n",
    "        if  token_text in ['containing','with','of','by','factors','toward','analysis','in'] and \\\n",
    "        left_token_text in ['buffer','medium','presence','inhibitors','inhibited','addition','fed',\\\n",
    "                           'salts','application','Application','environmental','combination','phase',\\\n",
    "                           'treated','binding','removal','tolerance','kinetic','reduced','Treatment',\\\n",
    "                           'treatment','cryopreserved','media']:\n",
    "            negtive_start = token_index   \n",
    "            #print(negtive_start)\n",
    "        \"\"\"\n",
    "        elif token_text in ['required']:\n",
    "            negtive_start = token_index\n",
    "        \"\"\"\n",
    "    for tok_i in tokens_index:\n",
    "        if tok_i > negtive_start:\n",
    "            negtive_end = tok_i\n",
    "            break\n",
    "    return (int(negtive_start),int(negtive_end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "def get_negtive_tokens_index(cand):\n",
    "    sentence = cand.sentence\n",
    "    #print(sentence)\n",
    "    tokens = negtivenlp(sentence)\n",
    "    tokens_len = len(tokens)\n",
    "    tokens_verb_index = [tok.i for tok in tokens if tok.pos_=='VERB']\n",
    "    tokens_verb_index.append(tokens_len)\n",
    "    #print(tokens_index)\n",
    "    negtive_start = tokens_len\n",
    "    negtive_end = tokens_len\n",
    "    negtive_index = []\n",
    "    negtive_start_list = []\n",
    "    for token in tokens:\n",
    "        try:\n",
    "            left_neigbor = token.nbor(-1)\n",
    "        except:\n",
    "            left_neigbor = token\n",
    "        token_text = token.text\n",
    "        token_pos = token.pos_\n",
    "        left_token_text = left_neigbor.text\n",
    "        token_index = token.i          \n",
    "        #print(token.text,\"-->\",token.pos_,\"-->\",token.i,\"-->\",left_neigbor.text)\n",
    "        if  token_text in ['containing','with','of','by','factors','toward','analysis','in','to',\\\n",
    "                           'concentrations','consisting'] and \\\n",
    "        left_token_text in ['buffer','medium','presence','inhibitors','inhibited','addition','fed',\\\n",
    "                           'salts','application','Application','environmental','combination','phase',\\\n",
    "                           'treated','binding','removal','tolerance','kinetic','reduced','Treatment',\\\n",
    "                           'treatment','cryopreserved','media','cultures','effects','resistant','substrate',\\\n",
    "                           'pretreatment','solution','use','removal','degradation']:\n",
    "            #negtive_start = token_index\n",
    "            negtive_start_list.append(token_index)\n",
    "            #print(negtive_start)\n",
    "        \"\"\"\n",
    "        elif token_text in ['required']:\n",
    "            negtive_start = token_index\n",
    "        \"\"\"\n",
    "    #print(negtive_start_list)\n",
    "    for neg_start in negtive_start_list:\n",
    "        sub_neg_index_list = []        \n",
    "        for tok_i in tokens_verb_index:\n",
    "            #print(\"tok_i\",tok_i)\n",
    "            if tok_i > neg_start:\n",
    "                #print(neg_start,tok_i+1)\n",
    "                sub_neg_index_list = [n_index for n_index in range(neg_start,tok_i+1)]\n",
    "                #print(sub_neg_index_list)\n",
    "                negtive_index.extend(sub_neg_index_list)\n",
    "                break\n",
    "        \n",
    "    negtive_index = list(set(negtive_index))\n",
    "    return negtive_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "def get_negtive_tokens_index_one(cand):\n",
    "    sentence = cand.sentence\n",
    "    #print(sentence)\n",
    "    tokens = negtivenlp(sentence)\n",
    "    tokens_len = len(tokens)\n",
    "    tokens_verb_index = [tok.i for tok in tokens if tok.pos_ in ['VERB','DET','SCONJ']]\n",
    "    tokens_verb_index.append(tokens_len)\n",
    "    #print(tokens_index)\n",
    "    negtive_start = tokens_len\n",
    "    negtive_end = tokens_len\n",
    "    negtive_index = []\n",
    "    negtive_start_list = []\n",
    "    for token in tokens:\n",
    "        try:\n",
    "            left_neigbor = token.nbor(-1)\n",
    "        except:\n",
    "            left_neigbor = token\n",
    "        token_text = token.text\n",
    "        token_pos = token.pos_\n",
    "        left_token_text = left_neigbor.text\n",
    "        token_index = token.i  \n",
    "\n",
    "        #print(token.text,\"-->\",token.pos_,\"-->\",token.i,\"-->\",left_neigbor.text)\n",
    "        if  token_text in ['added','adding','conditions','by','phase','during','inhibited',':',\"using\",\"spent\",\\\n",
    "                          'Neither','nor','when','limiting','after','through','Dissolved']:\n",
    "            #negtive_start = token_index\n",
    "            negtive_start_list.append(token_index)\n",
    "            #print(negtive_start)\n",
    "        \"\"\"\n",
    "        elif token_text in ['required']:\n",
    "            negtive_start = token_index\n",
    "        \"\"\"\n",
    "    #print(negtive_start_list)\n",
    "    for neg_start in negtive_start_list:\n",
    "        sub_neg_index_list = []        \n",
    "        for tok_i in tokens_verb_index:\n",
    "            #print(\"tok_i\",tok_i)\n",
    "            if tok_i > neg_start:\n",
    "                #print(neg_start,tok_i+1)\n",
    "                sub_neg_index_list = [n_index for n_index in range(neg_start,tok_i+1)]\n",
    "                #print(sub_neg_index_list)\n",
    "                negtive_index.extend(sub_neg_index_list)\n",
    "                break\n",
    "        \n",
    "    negtive_index = list(set(negtive_index))\n",
    "    return negtive_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.labeling import labeling_function\n",
    "@labeling_function()\n",
    "def lf_media_chem_negtive(x):\n",
    "    chem_word_left,chem_word_right = x.chem_word_idx\n",
    "    prod_word_left,prod_word_right = x.prod_word_idx\n",
    "    negtive_span_index_list = []\n",
    "    negtive_list1 = get_negtive_tokens_index(x)\n",
    "    negtive_span_index_list.extend(negtive_list1)   \n",
    "    negtive_list2 =  get_negtive_tokens_index_one(x)\n",
    "    negtive_span_index_list.extend(negtive_list2)\n",
    "    for word_right in [chem_word_right,prod_word_right]:\n",
    "        if word_right in negtive_span_index_list:\n",
    "            return NEGATIVE\n",
    "    return ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "def get_parse_tree_chem_negtive(x):\n",
    "    sentence = x.sentence\n",
    "    chem_pos_word = {}\n",
    "    for chem,chem_word in x.chem_pos_word.items():\n",
    "        chem_start,chem_end = chem.split(\"*#*\")\n",
    "        for chem_index in range(int(chem_start),int(chem_end)):\n",
    "            chem_pos_word[chem_index] = chem_word\n",
    "    \n",
    "    doc = treenlp(sentence)\n",
    "    # negtive_chems  with mark verb\n",
    "    noun_chunk_dct = {}\n",
    "    chem_word_index = {}\n",
    "    chem_word_root = {}\n",
    "    chem_head_children = {}\n",
    "    for chunk in doc.noun_chunks:\n",
    "        chunk_index = chunk.root.i\n",
    "        chem_word_index[chunk.root] = chunk_index\n",
    "        noun_chunk_dct[chunk.root] = chunk.root.head \n",
    "        chem_head_children[chunk.root] = [str(child)for child in chunk.root.head.head.children]\n",
    "        chem_word_root[chem_word] = chunk\n",
    "        if chunk.root.dep_ in ['conj','appos']:\n",
    "            try:\n",
    "                noun_chunk_dct[chunk.root] = noun_chunk_dct[chunk.root.head]\n",
    "            except:\n",
    "                continue\n",
    "    negtive_chems = []\n",
    "    negtiv_vocubs = ['disrupted','eliminated','included','reduced','assay','exerted','prevented','altered']\n",
    "    effect_vocubs = ['had']\n",
    "    for chem_root,chem_vocub in noun_chunk_dct.items():\n",
    "        chem_index = chem_word_index[chem_root]\n",
    "        \n",
    "        chem_word = chem_pos_word.get(chem_index,'')\n",
    "        if str(chem_word) and str(chem_vocub) in negtiv_vocubs:\n",
    "            negtive_chems.append(chem_word)\n",
    "        \n",
    "        if str(chem_word) and str(chem_vocub) in effect_vocubs:\n",
    "            chem_children = chem_head_children[chem_root]\n",
    "            if 'effect' in chem_children:\n",
    "                negtive_chems.append(chem_word)       \n",
    "            \n",
    "    # inhibitor chems \n",
    "    noun_chunk_dct = {}\n",
    "    chem_word_root = {}\n",
    "    negtive_chem_index = []\n",
    "    for chunk in doc.noun_chunks:\n",
    "        chunk_index = chunk.root.i        \n",
    "        noun_chunk_dct[chunk.root] = chunk_index\n",
    "        if chunk.root.dep_ in ['conj','appos']:\n",
    "            if str(chunk.root) in ['inhibitor']:\n",
    "                new_chunk_index = noun_chunk_dct[chunk.root.head]\n",
    "                negtive_chem_index.append(new_chunk_index)\n",
    "            if str(chunk.root.head) in ['inhibitor']:\n",
    "                negtive_chem_index.append(chunk_index)\n",
    "    inhibitor_chems = []\n",
    "    for i in negtive_chem_index:\n",
    "        inhibitor_chem = chem_pos_word.get(i,'')\n",
    "        if inhibitor_chem:\n",
    "            inhibitor_chems.append(inhibitor_chem)    \n",
    "    negtive_chems.extend(inhibitor_chems)\n",
    "    negtive_chems = list(set(negtive_chems))\n",
    "    return negtive_chems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "PrecursorTokens = {'from','using','on','via','as','containing','byproduct','in','presence','adding',\\\n",
    "                  'consumption'}\n",
    "#byproductMarker = {}\n",
    "left_negtive_tokens = PrecursorTokens\n",
    "right_negtive_tokens = {'consumed','conversion','substrate','did','plus','supplementation','dissociation'} #\n",
    "#titers of glucaric acid increased from unmeasurable to >0.8 g/L\n",
    "def get_precursors_prodchems(cand): \n",
    "    tokens = cand.tokens  \n",
    "    source_chems = ['glucose','carbon','sugar','xylose','lactose','sugar','sugars','ABE','sucrose',\\\n",
    "                   'Glucose','galactose']\n",
    "    salt_chems = ['Fe3+','Ca(2+)','NaCl','Mg(2+)','cadmium','Cu(2+)','iron','IPTG','water','N','nitrogen',\\\n",
    "                 'phosphorus','Ca','nitrate','CaCl2','isopropyl beta-D-thiogalactopyranoside','Tris',\\\n",
    "                 'zinc','Na+','Na(+)','salt','disulfide','CaSO(4)','AlCl(3)','borate','Al(3+)','phosphate','Fe(z+)',\\\n",
    "                 'CaCO(3)','oxygen','isopropyl-beta-d-thiogalactopyranoside','NaOH','NADPH','NaNO3','N','KCl',\\\n",
    "                 'phosphorous','Zn','Mn','Cu','Fe','CO','13C','NAH','Cd(2+)','inorganic phosphorus',\\\n",
    "                 'mixed liquor suspended solid','MLSS','OCrtZ','dihydrofolate','C-mol C-mol-1'] \n",
    "    source_chems.extend(salt_chems)    \n",
    "    precursors = source_chems\n",
    "    parse_tree_negtive_chems = get_parse_tree_chem_negtive(cand)\n",
    "    precursors.extend(parse_tree_negtive_chems)\n",
    "    chem_pos_word = cand.chem_pos_word\n",
    "    sent_chems = [chem for pos,chem in chem_pos_word.items()]\n",
    "    sent_chems = list(set(sent_chems))\n",
    "    cand_chems = cand.chems\n",
    "    cand_spans = get_multiple_prod_chem_spans(cand,cand_chems,tokens)\n",
    "    cand_span_pos_newpos = {}\n",
    "    for cand_span in cand_spans:\n",
    "        for i in range(1,len(cand_span)):\n",
    "            cand_span_pos_newpos[cand_span[i]] = cand_span[0]\n",
    "    #print(cand_span_pos_newpos,\"*\"*30)       \n",
    "    for chem in cand.chems:\n",
    "        #print(chem)\n",
    "        chem_word = chem_pos_word[chem]        \n",
    "        if chem in cand_span_pos_newpos.keys():\n",
    "            chem = cand_span_pos_newpos[chem]\n",
    "            #print(\"chem\",chem)\n",
    "        chem_start,chem_end = chem.split(\"*#*\")\n",
    "        chem_left_before = int(chem_start)\n",
    "        chem_right = int(chem_end)\n",
    "        #print(chem_left_before,'before',chem)\n",
    "        chem_left = get_chem_left_edge(cand,[chem_left_before,chem_right])\n",
    "        #print(chem_left,'after')\n",
    "\n",
    "        chem_left_tokens,chem_right_tokens = left_right_tokens_chem([chem_left,chem_right],tokens,window=1)\n",
    "        #print(chem_left_tokens,chem_right_tokens)\n",
    "        if len(right_negtive_tokens.intersection(set(chem_right_tokens))) > 0:\n",
    "            #print(\"chem_word\",chem_word,\"chem_right_tokens\",chem_right_tokens)\n",
    "            precursors.append(chem_word)\n",
    "        if len(PrecursorTokens.intersection(set(chem_left_tokens))) > 0:\n",
    "            #print(PrecursorTokens.intersection(set(chem_left_tokens)))\n",
    "            #print(\"chem_word\",chem_word,\"chem_left_tokens\",chem_left_tokens,'PrecursorTokens',PrecursorTokens)\n",
    "            precursors.append(chem_word)\n",
    "    precursors = list(set(precursors))\n",
    "    prodchems = [_chem for _chem in sent_chems if _chem not in precursors]\n",
    "    cand.precursors = precursors\n",
    "    cand.prodchems = prodchems\n",
    "    #print(\"precursors\",precursors,\"chems\",prodchems)\n",
    "    return cand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.labeling import labeling_function\n",
    "# Check for the `chem` words appearing between the chem and the prod\n",
    "#After selecting the best combination of genes, approximately 17.3 mg/L of 1,3-dihydroxy-9(10H)-acridone (DHA)\n",
    "#and 26.0 mg/L of 1,3-dihydroxy-10-methylacridone (NMA) were synthesized.\n",
    "PosiveLeftTokens = {'titer','titre','titers','titres','yield','yields','yielding'\\\n",
    "                      'produce','produced','producing','concentration','production','productivity',\\\n",
    "                    'obtain','obtained','achieved','generated','generate','accumulated','accumulation'\\\n",
    "                    'accumulate','resulting','achieving','achieve','achieved','reaching','reached',\\\n",
    "                    'synthesized','synthesis','leading','up','and'\n",
    "                  }\n",
    "SegmentTokens = {'consisting','using','in','was',',','and','from','with','per','at','were',')','(',\\\n",
    "                '.'}\n",
    "\n",
    "negtive_between_tokens = {'consisting','from','on','and','consumption'}\n",
    "@labeling_function(resources=dict(PosiveLeftTokens=PosiveLeftTokens,\\\n",
    "                                 SegmentTokens=SegmentTokens),\\\n",
    "                   pre=[get_chemnum_between_prod_chem])\n",
    "def lf_prod_chem_between_window_chemnum(x,PosiveLeftTokens,SegmentTokens):\n",
    "    x = get_precursors_prodchems(x)\n",
    "    precursors = x.precursors\n",
    "    chem_word = x.chem_word\n",
    "    if \"respectively\" in x.tokens:\n",
    "        return ABSTAIN\n",
    "    if chem_word in precursors:\n",
    "        return ABSTAIN    \n",
    "    if not x.prod_chem_order:\n",
    "        return ABSTAIN\n",
    "    \n",
    "    media_lable =lf_media_chem_negtive(x)\n",
    "    if media_lable == 0:\n",
    "        return ABSTAIN    \n",
    "\n",
    "    #print()\n",
    "    if x.between_prod_chem_chemnum > 0:\n",
    "        return ABSTAIN\n",
    "    else:\n",
    "        if chem_word in precursors:\n",
    "            return ABSTAIN\n",
    "        prod_left_tokens, prod_right_tokens = left_right_tokens_prod(x.prod_word_idx,x.tokens,window=2)\n",
    "        chem_word_left,chem_word_right = x.chem_word_idx\n",
    "        #print(\"*\"*20)\n",
    "        #print(type(chem_word_right))\n",
    "        #print(x.chem_word_idx)\n",
    "        window = 1\n",
    "        chem_right_token = x.tokens[chem_word_right:][0 : window]\n",
    "        #print(chem_word_right,chem_right_token)\n",
    "        if len(negtive_between_tokens.intersection(set(x.between_tokens)))>0:\n",
    "            return ABSTAIN\n",
    "        \n",
    "        if len(PosiveLeftTokens.intersection(set(prod_left_tokens))) > 0 \\\n",
    "        and len(SegmentTokens.intersection(set(chem_right_token)))>0 :\n",
    "            return POSITIVE\n",
    "        else:\n",
    "            return ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.labeling import labeling_function\n",
    "# Check for the `mark` words appearing between the chem and the prod\n",
    "# 3.80 g/L of icariside D2\n",
    "# achieving ~800 mg/L of jolkinol C and over 1 g/L total oxidized casbanes\n",
    "ProdChemBetweenOne = {\"of\",')'}\n",
    "@labeling_function(resources=dict(ProdChemBetweenOne=ProdChemBetweenOne),\\\n",
    "                  pre=[get_chemnum_between_prod_chem])\n",
    "def lf_prod_chem_between_window_markword(x, ProdChemBetweenOne):\n",
    "    x = get_precursors_prodchems(x)\n",
    "    precursors = x.precursors\n",
    "    chem_word = x.chem_word\n",
    "    if chem_word in precursors:\n",
    "        return ABSTAIN\n",
    "    if not x.prod_chem_order:\n",
    "        return ABSTAIN\n",
    "    media_lable =lf_media_chem_negtive(x)\n",
    "    if media_lable == 0:\n",
    "        return ABSTAIN  \n",
    "    #print(negtive_span_start, negtive_span_end)\n",
    "    prod_left_tokens, prod_right_tokens = left_right_tokens_prod(x.prod_word_idx,x.tokens,window=2)\n",
    "    chem_word_left,chem_word_right = x.chem_word_idx\n",
    "   \n",
    "    token_length = len(x.between_tokens)\n",
    "    if token_length == 0:\n",
    "        return POSITIVE\n",
    "    elif token_length == 1 and len(ProdChemBetweenOne.intersection(set(x.between_tokens))) > 0:\n",
    "        return POSITIVE  \n",
    "    else:\n",
    "        return ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.types import DataPoint\n",
    "from snorkel.preprocess import preprocessor\n",
    "@preprocessor()\n",
    "def get_chemnum_between_chem_prod(cand):\n",
    "    \"\"\"\n",
    "    Returns the chems num between chem and prod\n",
    "    \"\"\"\n",
    "    chem_word_idx = cand.chem_word_idx\n",
    "    prod_word_idx = cand.prod_word_idx\n",
    "    chem_start = chem_word_idx[0]\n",
    "    chem_end = chem_word_idx[1]\n",
    "    prod_start = prod_word_idx[0]\n",
    "    prod_end = prod_word_idx[1]\n",
    "    between_chemnum = 0    \n",
    "    if chem_end > prod_end:\n",
    "        between_chemnum += 1\n",
    "        chem_prod_order = False\n",
    "        cand.between_chem_prod_chemnum = between_chemnum\n",
    "        cand.chem_prod_order = chem_prod_order        \n",
    "        return cand\n",
    "    else:\n",
    "        chem_prod_order = True\n",
    "        left = chem_end + 1\n",
    "        right = prod_start\n",
    "    chem_prod_nums = [i for i in range(left,right)]\n",
    "    \n",
    "    for _chem in cand.chems:\n",
    "        chem_left = _chem.split(\"*#*\")[0]\n",
    "        if int(chem_left) in chem_prod_nums:\n",
    "            between_chemnum += 1\n",
    "    cand.between_chem_prod_chemnum = between_chemnum\n",
    "    cand.chem_prod_order = chem_prod_order\n",
    "    return cand            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "zingerone (70 mg/L, 0.36 mM)\n",
    "\"\"\"\n",
    "\n",
    "NegtiveBetweenToken = {'and',','}\n",
    "PosiveBetweenToken = {'titer','titre','titers','titres','yield','yields',\\\n",
    "                      'amount','concentration','production','productivity',\\\n",
    "                      '(','reaching','reached','synthesized'\n",
    "                  }\n",
    "@labeling_function(resources=dict(PosiveBetweenToken=PosiveBetweenToken,\\\n",
    "                                 NegtiveBetweenToken=NegtiveBetweenToken),\\\n",
    "                   pre=[get_chemnum_between_chem_prod])\n",
    "def lf_chem_prod_between_window_markword(x,NegtiveBetweenToken,PosiveBetweenToken):\n",
    "    \n",
    "    if \"respectively\" in x.tokens:\n",
    "        return ABSTAIN \n",
    "    \n",
    "    x = get_precursors_prodchems(x)\n",
    "    precursors = x.precursors\n",
    "    chem_word = x.chem_word\n",
    "    prod_word_idx = x.prod_word_idx\n",
    "   \n",
    "    if chem_word in precursors:\n",
    "        return ABSTAIN    \n",
    "\n",
    "    media_lable =lf_media_chem_negtive(x)\n",
    "    if media_lable == 0:\n",
    "        return ABSTAIN  \n",
    "    \n",
    "    if not x.chem_prod_order:\n",
    "        return ABSTAIN \n",
    "  \n",
    "    if x.between_chem_prod_chemnum == 0:\n",
    "        prod_text = \"{}*#*{}\".format(prod_word_idx[0],prod_word_idx[1])\n",
    "        prodpos_chemtext = get_clear_prodpos_chemtext(x)\n",
    "        if prodpos_chemtext:\n",
    "            if prod_text in prodpos_chemtext.keys():\n",
    "                clear_chem_text = prodpos_chemtext[prod_text]\n",
    "                if chem_word != clear_chem_text:\n",
    "                    return ABSTAIN          \n",
    "        if len(NegtiveBetweenToken.intersection(set(x.between_tokens)))>0:\n",
    "            #prod_left_token,prod_right_token = left_right_tokens(x)\n",
    "            prod_left_token,prod_right_token = left_right_tokens_prod(x.prod_word_idx,x.tokens,window=2)\n",
    "            if 'reaching' in x.between_tokens:\n",
    "                return POSITIVE\n",
    "            elif 'and' in prod_left_token and 'in' in prod_right_token:\n",
    "                return POSITIVE\n",
    "            elif ',' in prod_left_token and ')' in prod_right_token:\n",
    "                return POSITIVE            \n",
    "            elif ',' in x.between_tokens and 'which' in x.between_tokens and \\\n",
    "            len(PosiveBetweenToken.intersection(set(x.between_tokens)))>0:\n",
    "                return POSITIVE\n",
    "            else:\n",
    "                return ABSTAIN\n",
    "         \n",
    "        if len(PosiveBetweenToken.intersection(set(x.between_tokens)))>0:\n",
    "            return POSITIVE\n",
    "        else:\n",
    "            return ABSTAIN\n",
    "    else:\n",
    "        return ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#phenylalanine and 64 +- 3.7 mg/gDW (41 +- 2.3 mg/L) of tyrosine  \n",
    "#64 +- 3.7 mg/gDW pos are replaced by 41 +- 2.3 mg/L pos\n",
    "def prod_end_right_pos(candidate):\n",
    "    candidate_prods = candidate.prods\n",
    "    cand_span_chems=get_multiple_spans(candidate_prods,candidate.tokens)\n",
    "    cand_span_pos_newpos = {}\n",
    "    for cand_span_chem in cand_span_chems:\n",
    "        for i in range(len(cand_span_chem)-1):\n",
    "            cand_span_pos_newpos[cand_span_chem[i]] = cand_span_chem[-1]\n",
    "    #print(cand_span_pos_newpos)\n",
    "\n",
    "    return cand_span_pos_newpos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "phenylalanine and 64 +- 3.7 mg/gDW (41 +- 2.3 mg/L) of tyrosine #prod_end_right_pos\n",
    "\"\"\"\n",
    "NegtiveBetweenToken = {'and',','}\n",
    "@labeling_function(resources=dict(NegtiveBetweenToken=NegtiveBetweenToken),\\\n",
    "                   pre=[get_chemnum_between_chem_prod])\n",
    "def lf_chem_prod_between_window_negtiveword(x,NegtiveBetweenToken):\n",
    "    if not x.chem_prod_order:\n",
    "        return ABSTAIN\n",
    "    x = get_precursors_prodchems(x)\n",
    "    precursors = x.precursors\n",
    "\n",
    "    #prod_chem_label = [0]\n",
    "    if x.between_chem_prod_chemnum == 0:\n",
    "        chem_word = x.chem_word\n",
    "\n",
    "        prod_word_idx = x.prod_word_idx\n",
    "        prod_pos = prod_end_right_pos(x)   #64 +- 3.7 mg/gDW (41 +- 2.3 mg/L) of tyrosine\n",
    "        prod_pos_str = '*#*'.join([str(p_pos) for p_pos in x.prod_word_idx])\n",
    "        if prod_pos_str in prod_pos.keys():\n",
    "            prod_word_idx =[int(p_pos) for p_pos in prod_pos[prod_pos_str].split(\"*#*\")]\n",
    "        prod_pos_start,prod_pos_end = prod_word_idx\n",
    "        chem_prod_diff = [int(chem.split(\"*#*\")[0]) - prod_pos_end for chem in x.chems]\n",
    "        #print(chem_prod_diff,x.chems,x.prods)\n",
    "        \n",
    "        prod_left_token,prod_right_token = left_right_tokens_prod(prod_word_idx,x.tokens,window=2)\n",
    "        #print(prod_left_token,prod_right_token)\n",
    "        chem_left_token,chem_right_token = left_right_tokens_chem(x.chem_word_idx,x.tokens,window=2)\n",
    "        \n",
    "        chem_pos_start,chem_pos_end = x.chem_word_idx\n",
    "        #64.2 g/L acetoin(x.chem_word)  (prod_end, chem_start)\n",
    "        prod_chem_diff = [chem_pos_start - int(prod.split(\"*#*\")[1]) for prod in x.prods]\n",
    "        #\"\"\"\n",
    "        if 'from' in prod_left_token:\n",
    "            return NEGATIVE\n",
    "        #\"\"\"\n",
    "        if chem_word in precursors:\n",
    "            #print(\"$\"*50,chem_word)\n",
    "            return NEGATIVE\n",
    "        \n",
    "        if 0 in chem_prod_diff:\n",
    "            return NEGATIVE\n",
    "\n",
    "        elif 1 in chem_prod_diff:\n",
    "            \n",
    "            if 'of' in prod_right_token:\n",
    "                return NEGATIVE\n",
    "        elif 2 in chem_prod_diff:\n",
    "            #print(prod_right_token)\n",
    "            if 'of' in prod_right_token and ')' in prod_right_token:\n",
    "                return NEGATIVE\n",
    "        #627 +- 140 mg/L of psilocybin and 580 +- 276 mg/L of the dephosphorylated degradation product psilocin\n",
    "        if 'of' in prod_right_token:\n",
    "            return NEGATIVE\n",
    "\n",
    "        if 0 in prod_chem_diff:  #156 g/L glucose  (prod_end, chem_start)\n",
    "            return NEGATIVE\n",
    "        elif 1 in prod_chem_diff:\n",
    "            if 'of' in chem_left_token:\n",
    "                #print (\"&\"*30,prod_chem_diff)\n",
    "                return NEGATIVE\n",
    "            \n",
    "        if 'byproduct' in x.between_tokens:\n",
    "            return NEGATIVE\n",
    "        else:\n",
    "            return ABSTAIN\n",
    "\n",
    "   \n",
    "    else:\n",
    "        return ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "PosiveLeftToken = {'titer','titre','titers','titres','yield','yields',\\\n",
    "                      'amount','concentration','production','productivity',\\\n",
    "                   'synthesis','biosynthesis','accumulation','producing','produced',\\\n",
    "                   'overproduced'\n",
    "                  }\n",
    "\n",
    "@labeling_function(resources=dict(PosiveLeftToken=PosiveLeftToken),\n",
    "                   pre=[get_chemnum_between_chem_prod])\n",
    "def lf_chem_prod_first_titer(x,PosiveLeftToken):\n",
    "    x = get_precursors_prodchems(x)\n",
    "    precursors = x.precursors\n",
    "    chem_word = x.chem_word\n",
    "    if chem_word in precursors:\n",
    "        return ABSTAIN    \n",
    "\n",
    "    media_lable =lf_media_chem_negtive(x)\n",
    "    if media_lable == 0:\n",
    "        return ABSTAIN  \n",
    "        \n",
    "    if not x.chem_prod_order:\n",
    "        return ABSTAIN\n",
    "    \n",
    "    if x.between_chem_prod_chemnum > 0:\n",
    "        return ABSTAIN\n",
    "    \n",
    "    chem_word_idx = x.chem_word_idx\n",
    "    cand_tokens = x.tokens\n",
    "    window = 2\n",
    "    chem_word_neigbor_left = chem_word_idx[0]+1 - window\n",
    "    chem_word_neigbor_right = chem_word_idx[1]+ window\n",
    "    chem_neigbor_word=cand_tokens[chem_word_neigbor_left:chem_word_neigbor_right]\n",
    "    \n",
    "    chem_word_start =chem_word_idx[0] + 1\n",
    "    chem_word_end = chem_word_idx[1]       \n",
    "    prod_word_start = x.chem_word_idx[0]\n",
    "    chem_prod_nums = [i for i in range(chem_word_end,prod_word_start)]\n",
    "    between_prodnum = 0\n",
    "    for _prod in x.prods:\n",
    "        prod_left = _prod.split(\"*#*\")[0]\n",
    "        if int(prod_left) in chem_prod_nums:\n",
    "            between_prodnum += 1\n",
    "\n",
    "            \n",
    "    prod_left_token,prod_right_token = left_right_tokens_prod(x.prod_word_idx,x.tokens,window=1)\n",
    "    negtive_mark = {'substrate','consumption'}\n",
    "    if len(negtive_mark.intersection(set(prod_right_token)))>0:\n",
    "        return ABSTAIN            \n",
    "            \n",
    "            \n",
    "    if len(PosiveLeftToken.intersection(set(chem_neigbor_word))) > 0 and \\\n",
    "    between_prodnum == 0:\n",
    "        return POSITIVE\n",
    "    else:\n",
    "        return ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.labeling import labeling_function\n",
    "\n",
    "@labeling_function(pre=[get_precursors_prodchems])\n",
    "def lf_one_prodchem(x):\n",
    "    prodchems = x.prodchems\n",
    "    #precursors= x.precursors\n",
    "    chem_word = x.chem_word\n",
    "    prod_word_idx = x.prod_word_idx\n",
    "    if 'respectively' in x.tokens:\n",
    "        return ABSTAIN\n",
    "    \n",
    "    prod_text = \"{}*#*{}\".format(prod_word_idx[0],prod_word_idx[1])\n",
    "    if chem_word in prodchems and len(prodchems)==1:\n",
    "        media_lable =lf_media_chem_negtive(x)\n",
    "        if media_lable == 0:\n",
    "            return ABSTAIN\n",
    "        prod_left_token,prod_right_token = left_right_tokens_prod(prod_word_idx,x.tokens,window=1)\n",
    "        negtive_mark = {'substrate'}\n",
    "        if len(negtive_mark.intersection(set(prod_right_token)))>0:\n",
    "            return ABSTAIN\n",
    "        \n",
    "        \n",
    "        prodpos_chemtext = get_clear_prodpos_chemtext(x)\n",
    "        if prodpos_chemtext:\n",
    "            if prod_text in prodpos_chemtext.keys():\n",
    "                clear_chem_text = prodpos_chemtext[prod_text]\n",
    "                if chem_word == clear_chem_text:\n",
    "                    return POSITIVE\n",
    "                else:\n",
    "                    return ABSTAIN\n",
    "        return POSITIVE\n",
    "    else:\n",
    "        #print(\"i\"*20)\n",
    "        return ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.labeling import labeling_function\n",
    "\n",
    "@labeling_function(pre=[get_precursors_prodchems])\n",
    "def lf_one_prodchem_negtive(x):\n",
    "    #prodchems = x.prodchems\n",
    "    precursors= x.precursors\n",
    "    chem_word = x.chem_word\n",
    "    if chem_word in precursors:\n",
    "        return NEGATIVE\n",
    "    else:\n",
    "        return ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.labeling import labeling_function\n",
    "@labeling_function(pre=[get_precursors_prodchems])\n",
    "def lf_one_productivity(x):\n",
    "    prods= x.prods\n",
    "    precursors= x.precursors\n",
    "    prodchems = x.prodchems\n",
    "    chem_word = x.chem_word\n",
    "    chem_pos_word = x.chem_pos_word\n",
    "    cand_chems = x.chems\n",
    "    \n",
    "    cand_spans = get_multiple_spans(cand_chems,x.tokens)\n",
    "    #print(\"cand_chems:\",cand_chems,\"cand_spans\",cand_spans,\"chem_pos_word\",chem_pos_word)\n",
    "    \n",
    "    \n",
    "    chem_word = x.chem_word\n",
    "    if chem_word in precursors:\n",
    "        return ABSTAIN          \n",
    "    media_lable =lf_media_chem_negtive(x)\n",
    "    if media_lable == 0:\n",
    "        return ABSTAIN    \n",
    "\n",
    "    chem_words = []\n",
    "    if len(prods) > 1:\n",
    "        return ABSTAIN\n",
    "    if len(cand_spans) >0:\n",
    "                \n",
    "        for cand_span in cand_spans:\n",
    "            if len(cand_span) < 2:\n",
    "                return ABSTAIN            \n",
    "            for chem_span in cand_span:\n",
    "                sub_chem_word = chem_pos_word[chem_span]\n",
    "                if sub_chem_word in prodchems:\n",
    "                    chem_words.append(sub_chem_word)\n",
    "    else:\n",
    "        return ABSTAIN\n",
    "    #print(chem_words,chem_word)        \n",
    "    if chem_word in chem_words:\n",
    "        prod_word_idx = x.prod_word_idx\n",
    "        prod_text = \"{}*#*{}\".format(prod_word_idx[0],prod_word_idx[1])\n",
    "        prodpos_chemtext = get_clear_prodpos_chemtext(x)\n",
    "        if prodpos_chemtext:\n",
    "            if prod_text in prodpos_chemtext.keys():\n",
    "                clear_chem_text = prodpos_chemtext[prod_text]\n",
    "                if chem_word != clear_chem_text:\n",
    "                    return ABSTAIN\n",
    "        prod_left_token,prod_right_token = left_right_tokens_prod(prod_word_idx,x.tokens,window=1)\n",
    "\n",
    "        chem_word_idx = x.chem_word_idx\n",
    "        positive_mark = {'of','-'}\n",
    "        chem_prod_diff = chem_word_idx[0] - prod_word_idx[1]\n",
    "        if len(positive_mark.intersection(set(prod_right_token)))>0 and chem_prod_diff!= 1:\n",
    "            return ABSTAIN\n",
    "        negtive_mark = {'or'}\n",
    "        chem_left_token,chem_right_token = left_right_tokens_chem(chem_word_idx,x.tokens,window=1)        \n",
    "        if len(negtive_mark.intersection(set(chem_left_token)))>0:\n",
    "            return ABSTAIN        \n",
    "        return POSITIVE\n",
    "    else:\n",
    "        \n",
    "        return ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.labeling import labeling_function\n",
    "\n",
    "@labeling_function(pre=[get_precursors_prodchems])\n",
    "def lf_one_productivity_negtive(x):\n",
    "    prods= x.prods\n",
    "    precursors= x.precursors\n",
    "    #prodchems = x.prodchems\n",
    "    chem_word = x.chem_word\n",
    "    chem_pos_word = x.chem_pos_word\n",
    "    cand_chems = x.chems\n",
    "    cand_spans = get_multiple_spans(cand_chems,x.tokens)\n",
    "    #print(\"cand_spans\",cand_spans)\n",
    "    precursors_chem_words = []\n",
    "    if len(prods) > 1:\n",
    "        return ABSTAIN\n",
    "    if len(cand_spans) >0:\n",
    "        for cand_span in cand_spans:\n",
    "            if len(cand_span) < 2:\n",
    "                return ABSTAIN            \n",
    "            for chem_span in cand_span:\n",
    "                sub_chem_word = chem_pos_word[chem_span]\n",
    "                #if sub_chem_word in prodchems:\n",
    "                if sub_chem_word in precursors:\n",
    "                    precursors_chem_words.append(sub_chem_word)\n",
    "    else:\n",
    "        return ABSTAIN\n",
    "    #print(precursors_chem_words,chem_word)        \n",
    "    if chem_word in precursors_chem_words:\n",
    "        return NEGATIVE\n",
    "    else:\n",
    "        #print(\"i\"*20)\n",
    "        return ABSTAIN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mutiple_chem_prod_match(cand):\n",
    "    chem_word_poss = cand.chems\n",
    "    prod_word_poss = cand.prods\n",
    "    #chem_tokens_num = len(cand.tokens)\n",
    "    chem_word_span = get_multiple_spans(chem_word_poss,cand.tokens)\n",
    "    prod_word_span = get_multiple_spans(prod_word_poss,cand.tokens)\n",
    "    #print(\"chem_word_span\",chem_word_span)\n",
    "    #print(\"prod_word_span\",prod_word_span)\n",
    "    chem_prod_matches = []\n",
    "    for sub_chem_spans in chem_word_span:\n",
    "        for sub_prod_spans in prod_word_span:\n",
    "            if len(sub_prod_spans) != len(sub_chem_spans):\n",
    "                continue\n",
    "            for sub_chem_word,sub_prod_word in zip(sub_chem_spans,sub_prod_spans):\n",
    "                #print(sub_chem_word,sub_prod_word)\n",
    "                chem_prod_match = \"{}#*#{}\".format(sub_chem_word,sub_prod_word)\n",
    "                #print(chem_prod_match)\n",
    "                chem_prod_matches.append(chem_prod_match)\n",
    "    #print(chem_prod_matches)\n",
    "    cand.chem_prod_matches = chem_prod_matches\n",
    "    return cand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.labeling import labeling_function\n",
    "multiple_tokens = {'and',','}\n",
    "@labeling_function( resources=dict(multiple_tokens=multiple_tokens),\\\n",
    "                   pre=[get_mutiple_chem_prod_match])\n",
    "def lf_chem_prod_match(cand,multiple_tokens):\n",
    "    cand_tokens = cand.tokens\n",
    "    if \"respectively\" in cand_tokens:\n",
    "        cand = get_precursors_prodchems(cand)\n",
    "        precursors= cand.precursors\n",
    "        chem_word = cand.chem_word\n",
    "        if chem_word in precursors:\n",
    "            return ABSTAIN          \n",
    "        media_lable =lf_media_chem_negtive(cand)\n",
    "        if media_lable == 0:\n",
    "            return ABSTAIN  \n",
    "        \n",
    "        \n",
    "        chem_word_idx = cand.chem_word_idx\n",
    "        prod_word_idx = cand.prod_word_idx\n",
    "        if chem_word_idx[0] > prod_word_idx[0]:\n",
    "            return ABSTAIN\n",
    "        window = 2\n",
    "        chem_word_neigbor_left = chem_word_idx[0]- window\n",
    "        chem_word_neigbor_right = chem_word_idx[1]+ window\n",
    "        chem_neigbor_word=cand_tokens[chem_word_neigbor_left:chem_word_neigbor_right]\n",
    "        if len(multiple_tokens.intersection(set(chem_neigbor_word))) == 0:\n",
    "            return ABSTAIN\n",
    "        #print(chem_neigbor_word)\n",
    "        chem_poss = '{}*#*{}'.format(chem_word_idx[0],chem_word_idx[1])\n",
    "        prod_poss = '{}*#*{}'.format(prod_word_idx[0],prod_word_idx[1])\n",
    "        chem_prod_poss = \"{}#*#{}\".format(chem_poss,prod_poss)\n",
    "        if chem_prod_poss in cand.chem_prod_matches:\n",
    "            return POSITIVE\n",
    "        else:\n",
    "            return ABSTAIN        \n",
    "    else:\n",
    "        return ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.labeling import labeling_function\n",
    "multiple_tokens = {'and',','}\n",
    "@labeling_function( resources=dict(multiple_tokens=multiple_tokens),\\\n",
    "                   pre=[get_mutiple_chem_prod_match])\n",
    "def lf_chem_prod_not_match(cand,multiple_tokens):\n",
    "    cand_tokens = cand.tokens\n",
    "    if \"respectively\" in cand_tokens:\n",
    "        chem_word_idx = cand.chem_word_idx\n",
    "        prod_word_idx = cand.prod_word_idx\n",
    "        if chem_word_idx[0] > prod_word_idx[0]:\n",
    "            return ABSTAIN\n",
    "        window = 2\n",
    "        chem_word_neigbor_left = chem_word_idx[0]- window\n",
    "        chem_word_neigbor_right = chem_word_idx[1]+ window\n",
    "        chem_neigbor_word=cand_tokens[chem_word_neigbor_left:chem_word_neigbor_right]\n",
    "        if len(multiple_tokens.intersection(set(chem_neigbor_word))) == 0:\n",
    "            return ABSTAIN\n",
    "        #print(chem_neigbor_word)\n",
    "        chem_poss = '{}*#*{}'.format(chem_word_idx[0],chem_word_idx[1])\n",
    "        prod_poss = '{}*#*{}'.format(prod_word_idx[0],prod_word_idx[1])\n",
    "        chem_prod_poss = \"{}#*#{}\".format(chem_poss,prod_poss)\n",
    "        if not cand.chem_prod_matches:\n",
    "            return ABSTAIN \n",
    "        if chem_prod_poss in cand.chem_prod_matches:\n",
    "            return ABSTAIN\n",
    "        else:\n",
    "            return NEGATIVE        \n",
    "    else:\n",
    "        return ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.labeling import PandasLFApplier\n",
    "\n",
    "lfs = [\n",
    "    lf_prod_chem_between_window_chemnum,\n",
    "    lf_prod_chem_between_window_markword,\n",
    "    lf_chem_prod_between_window_markword,\n",
    "    lf_chem_prod_between_window_negtiveword,\n",
    "    lf_chem_prod_first_titer,\n",
    "    lf_one_prodchem,\n",
    "    lf_one_prodchem_negtive,\n",
    "    lf_media_chem_negtive,\n",
    "    lf_one_productivity,\n",
    "    lf_one_productivity_negtive,\n",
    "    lf_chem_prod_match,\n",
    "    lf_chem_prod_not_match,\n",
    "\n",
    "]\n",
    "\n",
    "applier = PandasLFApplier(lfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tianyu/opt/anaconda3/lib/python3.7/site-packages/tqdm/std.py:658: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n",
      "100%|██████████| 2063/2063 [05:03<00:00,  6.81it/s]\n",
      "100%|██████████| 2063/2063 [05:03<00:00,  6.79it/s]\n"
     ]
    }
   ],
   "source": [
    "from snorkel.labeling import LFAnalysis\n",
    "\n",
    "negtivenlp = spacy.load(\"en_core_web_sm\")\n",
    "L_dev = applier.apply(df_dev)\n",
    "L_train = applier.apply(df_dev)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.labeling.model import LabelModel\n",
    "\n",
    "label_model = LabelModel(cardinality=2, verbose=True)\n",
    "label_model.fit(L_train, Y_dev, n_epochs=5000, log_freq=500, seed=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label model f1 score: 0.781582054309327\n",
      "Label model roc-auc: 0.9125938996068865\n"
     ]
    }
   ],
   "source": [
    "from snorkel.analysis import metric_score\n",
    "from snorkel.utils import probs_to_preds\n",
    "\n",
    "probs_dev = label_model.predict_proba(L_dev)\n",
    "preds_dev = probs_to_preds(probs_dev)\n",
    "print(\n",
    "    f\"Label model f1 score: {metric_score(Y_dev, preds_dev, probs=probs_dev, metric='f1')}\"\n",
    ")\n",
    "print(\n",
    "    f\"Label model roc-auc: {metric_score(Y_dev, preds_dev, probs=probs_dev, metric='roc_auc')}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_model.save('../ProcessedData/procon_saved_label_model.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
